{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Python imports\n",
    "from time import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "np.random.seed(7)\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, train_file_name, num_negatives_train=5):\n",
    "        self.trainMatrix = self.load_rating_file_as_matrix(train_file_name)\n",
    "        self.num_users, self.num_items = self.trainMatrix.shape\n",
    "        self.user_input, self.item_input, self.ratings = self.get_train_instances(self.trainMatrix, num_negatives_train)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_input)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_input[index]\n",
    "        item_id = self.item_input[index]\n",
    "        rating = self.ratings[index]\n",
    "\n",
    "        return {'user_id': user_id,\n",
    "                'item_id': item_id,\n",
    "                'rating': rating}\n",
    "\n",
    "    def get_train_instances(self, train, num_negatives):\n",
    "        user_input, item_input, ratings = [], [], []\n",
    "        num_users, num_items = train.shape\n",
    "        for (u, i) in train.keys():\n",
    "            # positive instance\n",
    "            user_input.append(u)\n",
    "            item_input.append(i)\n",
    "            ratings.append(1)\n",
    "            # negative instances\n",
    "            for _ in range(num_negatives):\n",
    "                j = np.random.randint(1, num_items)\n",
    "                # while train.has_key((u, j)):\n",
    "                while (u, j) in train:\n",
    "                    j = np.random.randint(1, num_items)\n",
    "                user_input.append(u)\n",
    "                item_input.append(j)\n",
    "                ratings.append(0)\n",
    "        return user_input, item_input, ratings\n",
    "\n",
    "    def load_rating_file_as_matrix(self, filename):\n",
    "        # Get number of users and items\n",
    "        num_users, num_items = 0, 0\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                u, i = int(arr[0]), int(arr[1])\n",
    "                num_users = max(num_users, u)\n",
    "                num_items = max(num_items, i)\n",
    "                line = f.readline()\n",
    "        # Construct matrix\n",
    "        mat = sp.dok_matrix((num_users+1, num_items+1), dtype=np.float32)\n",
    "        with open(filename, \"r\") as f:\n",
    "            line = f.readline()\n",
    "            while line != None and line != \"\":\n",
    "                arr = line.split(\"\\t\")\n",
    "                user, item, rating = int(arr[0]), int(arr[1]), float(arr[2])\n",
    "                if (rating > 0):\n",
    "                    mat[user, item] = 1.0\n",
    "                line = f.readline()\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, n_users, n_items, layers=[16, 8], dropout=False):\n",
    "        super().__init__()\n",
    "        assert (layers[0] % 2 == 0), \"layers[0] must be an even number\"\n",
    "        self.__alias__ = \"MLP {}\".format(layers)\n",
    "        self.__dropout__ = dropout\n",
    "\n",
    "        # user and item embedding layers\n",
    "        embedding_dim = int(layers[0]/2)\n",
    "        self.user_embedding = torch.nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = torch.nn.Embedding(n_items, embedding_dim)\n",
    "\n",
    "        # list of weight matrices\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        # hidden dense layers\n",
    "        for _, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "        # final prediction layer\n",
    "        self.output_layer = torch.nn.Linear(layers[-1], 1)\n",
    "\n",
    "    def forward(self, feed_dict):\n",
    "        users = feed_dict['user_id']\n",
    "        items = feed_dict['item_id']\n",
    "        user_embedding = self.user_embedding(users)\n",
    "        item_embedding = self.item_embedding(items)\n",
    "        # concatenate user and item embeddings to form input\n",
    "        x = torch.cat([user_embedding, item_embedding], 1)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            x = self.fc_layers[idx](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x,  p=self.__dropout__, training=self.training)\n",
    "        logit = self.output_layer(x)\n",
    "        rating = torch.sigmoid(logit)\n",
    "        return rating\n",
    "\n",
    "    def predict(self, feed_dict):\n",
    "        # return the score, inputs and outputs are numpy arrays\n",
    "        for key in feed_dict:\n",
    "            if type(feed_dict[key]) != type(None):\n",
    "                feed_dict[key] = torch.from_numpy(\n",
    "                    feed_dict[key]).to(dtype=torch.long, device=device)\n",
    "        output_scores = self.forward(feed_dict)\n",
    "        return output_scores.cpu().detach().numpy()\n",
    "\n",
    "    def get_alias(self):\n",
    "        return self.__alias__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, data_loader, loss_fn, optimizer, device):\n",
    "    t1 = time()\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    for feed_dict in data_loader:\n",
    "        for key in feed_dict:\n",
    "            if type(feed_dict[key]) != type(None):\n",
    "                feed_dict[key] = feed_dict[key].to(dtype = torch.long, device = device)\n",
    "        prediction = model(feed_dict)\n",
    "        rating = feed_dict['rating']\n",
    "      \n",
    "        rating = rating.float().view(prediction.size())  \n",
    "        loss = loss_fn(prediction, rating)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "    epoch_loss = np.mean(epoch_loss)\n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_data_path = 'Data/movielens.train_implicit_ds'\n",
    "    layers = eval('[16,32,16,8]')\n",
    "    weight_decay = 0.00001\n",
    "    num_negatives_train = 4\n",
    "    num_negatives_test = 100\n",
    "    dropout = 0\n",
    "    learner = 'adam'\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 256\n",
    "    epochs = 30\n",
    "\n",
    "    topK = 10\n",
    "\n",
    "    full_dataset = MovieLensDataset(train_data_path, num_negatives_train=num_negatives_train)\n",
    "    \n",
    "    train = full_dataset.trainMatrix\n",
    "    num_users, num_items = train.shape\n",
    "\n",
    "    training_data_generator = DataLoader(full_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    model = MLP(num_users, num_items, layers=layers, dropout=dropout)\n",
    "\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = train_one_epoch(model, training_data_generator, loss_fn, optimizer, device)\n",
    "        print(\"Epoch = {} loss = {}\".format(epoch, epoch_loss))\n",
    "        \n",
    "    test_items = np.load('../Data/test_items.npy', allow_pickle=True)\n",
    "    test_users = np.load('../Data/test_users.npy', allow_pickle=True)\n",
    "    predictions = []\n",
    "    for users, items in zip(test_users, test_items):\n",
    "        feed_dict={'user_id': users, 'item_id': items}\n",
    "        p = model.predict(feed_dict)\n",
    "        predictions.append(p)\n",
    "    \n",
    "    np.save('Predictions/mlp', predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0 loss = 0.4368752856895289\n",
      "Epoch = 1 loss = 0.363552815384335\n",
      "Epoch = 2 loss = 0.3566942249850709\n",
      "Epoch = 3 loss = 0.3530544972234918\n",
      "Epoch = 4 loss = 0.349941099721948\n",
      "Epoch = 5 loss = 0.3468975736035241\n",
      "Epoch = 6 loss = 0.3432164560531769\n",
      "Epoch = 7 loss = 0.33800392281023417\n",
      "Epoch = 8 loss = 0.33125228371269017\n",
      "Epoch = 9 loss = 0.3247277679831483\n",
      "Epoch = 10 loss = 0.31915132159256504\n",
      "Epoch = 11 loss = 0.31444638052652046\n",
      "Epoch = 12 loss = 0.31053612923745344\n",
      "Epoch = 13 loss = 0.30703486965762244\n",
      "Epoch = 14 loss = 0.3038026545090885\n",
      "Epoch = 15 loss = 0.30069175192398\n",
      "Epoch = 16 loss = 0.29755062993028675\n",
      "Epoch = 17 loss = 0.2944786645106259\n",
      "Epoch = 18 loss = 0.2915656596345187\n",
      "Epoch = 19 loss = 0.28892169788826344\n",
      "Epoch = 20 loss = 0.2866338291448524\n",
      "Epoch = 21 loss = 0.2844755217625497\n",
      "Epoch = 22 loss = 0.2827113013935952\n",
      "Epoch = 23 loss = 0.28096287657894214\n",
      "Epoch = 24 loss = 0.2793001576911571\n",
      "Epoch = 25 loss = 0.2778460839691088\n",
      "Epoch = 26 loss = 0.2763638101498902\n",
      "Epoch = 27 loss = 0.2751731357217143\n",
      "Epoch = 28 loss = 0.27363984047288425\n",
      "Epoch = 29 loss = 0.2726821588145362\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semester_3",
   "language": "python",
   "name": "semester_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
